{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution Guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary pyhton modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/4GeeksAcademy/decision-tree-project-tutorial/main/diabetes.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guide on inspection of the dataset\n",
    "\n",
    "\n",
    "- Verify if there are Null / Nan Values\n",
    "\n",
    "- Is it a Balanced or Imbalanced Dataset?\n",
    "\n",
    "- Convert non numerical data to numerical\n",
    "\n",
    "- Find correlation - feature importance\n",
    "\n",
    "- Get some Statistics - mean,median,25%,50%,75%,count , min,max on coloum wise\n",
    "\n",
    "- Eliminate outliers with IQR Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Is it balanced or imbalanced?\n",
    "\n",
    "df[\"Outcome\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminating Outliers with IQR Method\n",
    "q1 = df['Insulin'].quantile(0.25)\n",
    "q3 = df['Insulin'].quantile(0.75)\n",
    "IQR = q3 - q1\n",
    "lower_limit = q1 - 1.5 * IQR\n",
    "upper_limit = q3 + 1.5 * IQR\n",
    "\n",
    "df = df[(df['Insulin'] > lower_limit) & (df['Insulin'] < upper_limit)]\n",
    "\n",
    "q1 = df['Age'].quantile(0.25)\n",
    "q3 = df['Age'].quantile(0.75)\n",
    "IQR = q3 - q1\n",
    "lower_limit = q1 - 1.5 * IQR\n",
    "upper_limit = q3 + 1.5 * IQR\n",
    "\n",
    "df = df[(df['Age'] > lower_limit) & (df['Age'] < upper_limit)]\n",
    "\n",
    "q1 = df['Glucose'].quantile(0.25)\n",
    "q3 = df['Glucose'].quantile(0.75)\n",
    "IQR = q3 - q1\n",
    "lower_limit = q1 - 1.5 * IQR\n",
    "upper_limit = q3 + 1.5 * IQR\n",
    "\n",
    "df = df[(df['Glucose'] > lower_limit) & (df['Glucose'] < upper_limit)]\n",
    "\n",
    "q1 = df['BMI'].quantile(0.25)\n",
    "q3 = df['BMI'].quantile(0.75)\n",
    "IQR = q3 - q1\n",
    "lower_limit = q1 - 1.5 * IQR\n",
    "upper_limit = q3 + 1.5 * IQR\n",
    "\n",
    "df = df[(df['BMI'] > lower_limit) & (df['BMI'] < upper_limit)]\n",
    "\n",
    "q1 = df['Pregnancies'].quantile(0.25)\n",
    "q3 = df['Pregnancies'].quantile(0.75)\n",
    "IQR = q3 - q1\n",
    "lower_limit = q1 - 1.5 * IQR\n",
    "upper_limit = q3 + 1.5 * IQR\n",
    "\n",
    "df = df[(df['Pregnancies'] > lower_limit) & (df['Pregnancies'] < upper_limit)]\n",
    "\n",
    "q1 = df['DiabetesPedigreeFunction'].quantile(0.25)\n",
    "q3 = df['DiabetesPedigreeFunction'].quantile(0.75)\n",
    "IQR = q3 - q1\n",
    "lower_limit = q1 - 1.5 * IQR\n",
    "upper_limit = q3 + 1.5 * IQR\n",
    "\n",
    "df = df[(df['DiabetesPedigreeFunction'] > lower_limit) & (df['DiabetesPedigreeFunction'] < upper_limit)]\n",
    "plt.figure(figsize=(13,5))\n",
    "sns.boxplot(data=df,orient='h')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find correlations\n",
    "\n",
    "print(df.corr())\n",
    "f, ax = plt.subplots(figsize=(16, 12))\n",
    "sns.heatmap(df.corr(), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the data to make a more balanced dataset\n",
    "\n",
    "from sklearn.utils import resample\n",
    "df_majority = df[(df[\"Outcome\"]==0)]\n",
    "df_minority = df[(df[\"Outcome\"]==1)]\n",
    "df_minority_upsampled = resample(df_minority,replace=True,n_samples=500,random_state=42)\n",
    "df = pd.concat([df_minority_upsampled,df_majority])\n",
    "df[\"Outcome\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some statistics\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate features from target\n",
    "\n",
    "X=df.drop('Outcome',axis='columns')\n",
    "Y=df[\"Outcome\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale the features\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data\n",
    "\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling with Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the data\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the score of train data just to verify its 1.\n",
    "\n",
    "model.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the score of your predictions\n",
    "\n",
    "model.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the confusion matrix\n",
    "\n",
    "print(confusion_matrix(Y_test,model.predict(X_test)))\n",
    "sns.heatmap(confusion_matrix(Y_test,model.predict(X_test)), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the classification report\n",
    "\n",
    "print(classification_report(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print feature importance\n",
    "\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the number of leaves\n",
    "\n",
    "print(model.get_n_leaves())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your tree params\n",
    "\n",
    "print(model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your tree depth\n",
    "\n",
    "print(dt_model.get_depth())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Decision tree with entropy criterion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "dt_model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(Y_test,dt_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test, dt_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(Y_test,dt_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dt_model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dt_model.get_n_leaves())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dt_model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dt_model.get_depth())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tune your decision tree hyperparameters using GridSearch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Grid Search to get best hyperparameters\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "tree_para = {'criterion':['gini','entropy'],'max_depth':[4,5,6,7,8,9,10,11,12,15,20,30,40,50,70,90,120,150],'min_samples_split': [2, 3, 4]}\n",
    "clf = GridSearchCV(DecisionTreeClassifier(), tree_para, cv=5)\n",
    "clf.fit(X_train,Y_train)\n",
    "print(clf.best_params_)\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Once you train your model with your tuned hyperparameters, use the roc_auc_curve to measure your results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train with the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Measure your results\n",
    "\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "fpr,tpr, thresholds = roc_curve(Y_test,dt_model.predict_proba(X_test)[:,1])\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.plot([0,1],[0,1],color=\"navy\",lw=2,label=\"Random-Model\")\n",
    "plt.plot(fpr,tpr,color=\"darkorange\",lw=2, label=\"Decision Tree- Model\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver operating characteristic :ROC-AUC\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(\"Computed Area Under the Curve (AUC)\",auc(fpr, tpr))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
